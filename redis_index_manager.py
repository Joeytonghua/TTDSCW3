import redis
import json
import msgpack
import zlib
import os
import time
from index_optimizer import IndexOptimizer


class RedisIndexManager:
    """ç®¡ç†Redisä¸­çš„ç´¢å¼•æ•°æ®"""

    def __init__(self, host='localhost', port=6379, db=0,
                 index_key='inverted_index',
                 optimized_index_file="optimized_index.msgpack",
                 original_index_file="inverted_index.json"):
        """
        åˆå§‹åŒ–Redisç´¢å¼•ç®¡ç†å™¨

        å‚æ•°:
        - host: RedisæœåŠ¡å™¨ä¸»æœº
        - port: RedisæœåŠ¡å™¨ç«¯å£
        - db: Redisæ•°æ®åº“ç¼–å·
        - index_key: Redisä¸­å­˜å‚¨ç´¢å¼•çš„é”®å
        - optimized_index_file: ä¼˜åŒ–ç´¢å¼•æ–‡ä»¶è·¯å¾„
        - original_index_file: åŸå§‹ç´¢å¼•æ–‡ä»¶è·¯å¾„
        """
        self.redis_client = redis.Redis(host=host, port=port, db=db, decode_responses=False)
        self.index_key = index_key
        self.optimized_index_file = optimized_index_file
        self.original_index_file = original_index_file

        # å†…å­˜ä¸­çš„ç¼“å­˜
        self._index_cache = None
        self._doc_id_map = None
        self._reverse_doc_id_map = None

    def is_index_in_redis(self):
        """æ£€æŸ¥Redisä¸­æ˜¯å¦å·²æœ‰ç´¢å¼•"""
        return self.redis_client.exists(self.index_key)

    def load_index_to_redis(self):
        """å°†ä¼˜åŒ–ç´¢å¼•åŠ è½½åˆ°Redisä¸­"""
        # é¦–å…ˆæ£€æŸ¥ä¼˜åŒ–ç´¢å¼•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.optimized_index_file):
            # ä¼˜åŒ–ç´¢å¼•ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ª
            print(f"ğŸ“Œ ä¼˜åŒ–ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¼€å§‹åˆ›å»º: {self.optimized_index_file}")
            IndexOptimizer.compress_index(self.original_index_file, self.optimized_index_file)

        # åŠ è½½ä¼˜åŒ–ç´¢å¼•
        try:
            with open(self.optimized_index_file, "rb") as f:
                compressed_data = f.read()

            # å­˜å‚¨åˆ°Redis
            print(f"ğŸ“¤ æ­£åœ¨å°†ä¼˜åŒ–ç´¢å¼•ä¸Šä¼ åˆ°Redis (å¤§å°: {len(compressed_data) / (1024 * 1024):.2f} MB)...")
            self.redis_client.set(self.index_key, compressed_data)
            print("âœ… ç´¢å¼•å·²æˆåŠŸåŠ è½½åˆ°Redis")
            return True
        except Exception as e:
            print(f"âŒ ç´¢å¼•åŠ è½½åˆ°Rediså¤±è´¥: {str(e)}")
            return False

    def get_index(self):
        """
        è·å–ç´¢å¼•ï¼Œä¼˜å…ˆä»å†…å­˜ç¼“å­˜ä¸­è·å–ï¼Œå…¶æ¬¡ä»Redisè·å–
        è¿”å›å…ƒç»„: (ç´¢å¼•å­—å…¸, æ–‡æ¡£IDæ˜ å°„)
        """
        # å¦‚æœå†…å­˜ä¸­å·²æœ‰ç¼“å­˜ï¼Œç›´æ¥è¿”å›
        if self._index_cache is not None and self._doc_id_map is not None:
            return self._index_cache, self._doc_id_map

        # å°è¯•ä»Redisè·å–
        try:
            compressed_data = self.redis_client.get(self.index_key)
            if not compressed_data:
                # Redisä¸­ä¸å­˜åœ¨ç´¢å¼•ï¼Œå°è¯•åŠ è½½
                if not self.load_index_to_redis():
                    raise Exception("æ— æ³•åŠ è½½ç´¢å¼•åˆ°Redis")
                compressed_data = self.redis_client.get(self.index_key)

            # è§£å‹ç¼©å’Œååºåˆ—åŒ– - æ·»åŠ strict_map_key=Falseå‚æ•°
            decompressed_data = zlib.decompress(compressed_data)
            optimized_data = msgpack.unpackb(decompressed_data, raw=False, strict_map_key=False)

            # ç¼“å­˜åˆ°å†…å­˜
            self._doc_id_map = optimized_data["doc_id_map"]
            self._index_cache = optimized_data["index"]

            # åˆ›å»ºåå‘æ˜ å°„ (æ•´æ•°ID -> åŸå§‹ID)
            self._reverse_doc_id_map = {v: k for k, v in self._doc_id_map.items()}

            return self._index_cache, self._doc_id_map

        except Exception as e:
            print(f"âŒ ä»RedisåŠ è½½ç´¢å¼•å¤±è´¥: {str(e)}")
            # å¦‚æœRedisåŠ è½½å¤±è´¥ï¼Œç›´æ¥ä»ä¼˜åŒ–æ–‡ä»¶åŠ è½½
            try:
                optimized_data = IndexOptimizer.decompress_index(self.optimized_index_file)
                if optimized_data:
                    self._doc_id_map = optimized_data["doc_id_map"]
                    self._index_cache = optimized_data["index"]
                    self._reverse_doc_id_map = {v: k for k, v in self._doc_id_map.items()}
                    return self._index_cache, self._doc_id_map
            except Exception as e2:
                print(f"âŒ ä»ä¼˜åŒ–æ–‡ä»¶åŠ è½½ç´¢å¼•å¤±è´¥: {str(e2)}")

            # å¦‚æœä¼˜åŒ–æ–‡ä»¶ä¹ŸåŠ è½½å¤±è´¥ï¼Œå°è¯•ä»åŸå§‹JSONåŠ è½½
            print(f"âš ï¸ å°è¯•ä»åŸå§‹JSONåŠ è½½ç´¢å¼• ({self.original_index_file})...")
            try:
                with open(self.original_index_file, "r", encoding="utf-8") as f:
                    original_index = json.load(f)

                # ä½¿ç”¨åŸå§‹ç´¢å¼•ï¼Œä½†æ²¡æœ‰IDä¼˜åŒ–
                self._index_cache = original_index
                self._doc_id_map = {}
                return self._index_cache, self._doc_id_map
            except Exception as e3:
                print(f"âŒ æ‰€æœ‰ç´¢å¼•åŠ è½½æ–¹æ³•å‡å¤±è´¥: {str(e3)}")
                return {}, {}

    def get_original_doc_id(self, int_doc_id):
        """å°†æ•´æ•°æ–‡æ¡£IDè½¬æ¢å›åŸå§‹æ–‡æ¡£ID"""
        if self._reverse_doc_id_map is None:
            # ç¡®ä¿æ˜ å°„å·²åŠ è½½
            self.get_index()

        return self._reverse_doc_id_map.get(int_doc_id, str(int_doc_id))

    def get_term_postings(self, term):
        """è·å–æŸä¸ªè¯çš„å€’æ’è®°å½•ï¼Œå¹¶è½¬æ¢å›åŸå§‹æ ¼å¼"""
        index, _ = self.get_index()

        # ç¡®ä¿æŸ¥è¯¢è¯è½¬æ¢ä¸ºå°å†™ä»¥åŒ¹é…ç´¢å¼•
        term = term.lower()

        if term not in index:
            # å°è¯•æŸ¥æ‰¾å¤§å°å†™å˜ä½“
            for indexed_term in index.keys():
                if indexed_term.lower() == term:
                    term = indexed_term
                    break
            else:
                return {}  # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŒ¹é…ï¼Œè¿”å›ç©ºç»“æœ

        # è·å–è¯¥è¯çš„å€’æ’è®°å½•
        postings = index[term]

        # è½¬æ¢ä¸ºåŸå§‹æ ¼å¼
        original_postings = {}
        for int_doc_id, diff_positions in postings.items():
            # è·å–åŸå§‹æ–‡æ¡£ID
            doc_id = self.get_original_doc_id(int_doc_id)

            # è¿˜åŸå·®åˆ†ç¼–ç çš„ä½ç½®
            positions = []
            if diff_positions:
                current_pos = 0
                for diff in diff_positions:
                    current_pos += diff
                    positions.append(current_pos)

            # ä½¿ç”¨åŸå§‹æ ¼å¼å­˜å‚¨
            original_postings[doc_id] = {
                "positions": positions
            }

        return original_postings

    def get_document_ids_for_term(self, term):
        """è·å–åŒ…å«æŸä¸ªè¯çš„æ‰€æœ‰æ–‡æ¡£ID"""
        postings = self.get_term_postings(term)
        return list(postings.keys())


# åˆ›å»ºå…¨å±€å®ä¾‹ï¼Œç”¨äºåº”ç”¨ä¸­è®¿é—®
index_manager = RedisIndexManager()

if __name__ == "__main__":
    # æµ‹è¯•ç´¢å¼•åŠ è½½å’ŒæŸ¥è¯¢
    manager = RedisIndexManager()
    if not manager.is_index_in_redis():
        manager.load_index_to_redis()

    # åŠ è½½ç´¢å¼•
    index, doc_id_map = manager.get_index()
    print(f"ç´¢å¼•åŒ…å« {len(index)} ä¸ªè¯æ¡")
    print(f"æ–‡æ¡£IDæ˜ å°„åŒ…å« {len(doc_id_map)} ä¸ªæ–‡æ¡£")

    # æµ‹è¯•æŸ¥è¯¢æŸä¸ªè¯
    test_term = next(iter(index.keys()))
    print(f"æµ‹è¯•æŸ¥è¯¢è¯: {test_term}")
    postings = manager.get_term_postings(test_term)
    print(f"åŒ…å«è¯¥è¯çš„æ–‡æ¡£æ•°: {len(postings)}")